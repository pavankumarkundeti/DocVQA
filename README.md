# DocVQA
This repository contains the dataset and code for reproducing results of the DocVQA paper, an exploration into Document Visual Question Answering using BERT and M4C models.
Paper can be found here - [DocVQA: A Dataset for VQA on Document Images](https://arxiv.org/abs/2007.00398)


## Dataset

The DocVQA dataset includes over 12,000 document images with more than 50,000 questions designed for Visual Question Answering tasks.

## Code

The codebase includes scripts for training and evaluating BERT and M4C models on the DocVQA dataset.

### Installation

Instructions for setting up the environment and installing dependencies.

```bash
pip install -r requirements.txt
